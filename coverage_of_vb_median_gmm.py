# -*- coding: utf-8 -*-
"""coverage of vb_median_gmm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14m0g1qHJ7zBrIDjRKi_GIGPIrl8AAIC2

## GMMOT
"""

pip install POT

import numpy as np
import ot
import scipy.stats as sps
import scipy.linalg as spl
from scipy.optimize import linprog
import matplotlib.pyplot as plt

###############################
### Optimal Transport between Gaussians (quadratic Wasserstein)
###############################

import numpy as np
from scipy.spatial.distance import cdist, euclidean

def geometric_median(X, eps=1e-5):
    y = np.mean(X, 0)

    while True:
        D = cdist(X, [y])
        nonzeros = (D != 0)[:, 0]

        Dinv = 1 / D[nonzeros]
        Dinvs = np.sum(Dinv)
        W = Dinv / Dinvs
        T = np.sum(W * X[nonzeros], 0)

        num_zeros = len(X) - np.sum(nonzeros)
        if num_zeros == 0:
            y1 = T
        elif num_zeros == len(X):
            return y
        else:
            R = (T - y) * Dinvs
            r = np.linalg.norm(R)
            rinv = 0 if r == 0 else num_zeros/r
            y1 = max(0, 1-rinv)*T + min(1, rinv)*y

        if euclidean(y, y1) < eps:
            return y1

        y = y1

def GaussianW2(m0,m1,Sigma0,Sigma1):
    # compute the quadratic Wasserstein distance between two Gaussians with means m0 and m1 and covariances Sigma0 and Sigma1
    Sigma00  = spl.sqrtm(Sigma0)
    Sigma010 = spl.sqrtm(Sigma00@Sigma1@Sigma00)
    d        = np.linalg.norm(m0-m1)**2+np.trace(Sigma0+Sigma1-2*Sigma010)
    return d

def GaussianW2_1D(m0, m1, Sigma0, Sigma1):
    # Compute the quadratic Wasserstein distance between two 1D Gaussians with means m0 and m1 and variances Sigma0 and Sigma1
    d = (m0 - m1)**2 + (np.sqrt(Sigma0) - np.sqrt(Sigma1)) ** 2
    return d


def GaussianMap(m0,m1,Sigma0,Sigma1,x):
    # Compute the OT map (evaluated at x) between two Gaussians with means m0 and m1 and covariances Sigma0 and Sigma1
    # m0 and m1 must be 2D arrays of size 1xd
    # Sigma0 and Sigma1 must be 2D arrays of size dxd
    # x can be a matrix of size n x d,
    # each column of x is a vector to which the function is applied
    d = Sigma0.shape[0]
    m0 = m0.reshape(1,d)
    m1 = m1.reshape(1,d)
    Sigma0 = Sigma0.reshape(d,d)
    Sigma1 = Sigma1.reshape(d,d)
    Sigma  = np.linalg.inv(Sigma0)@spl.sqrtm(Sigma0@Sigma1)
    Tx        = m1+(x-m0)@Sigma
    return Tx


import numpy as np
import scipy.linalg as spl

def GaussianBarycenterW2_1D(mu, Sigma, alpha, N):
    # Compute the W2 barycenter between several 1D Gaussians
    # mu has size K, with K the number of Gaussians
    # Sigma has size K
    K = mu.shape[0]  # number of Gaussians
    Sigman = 1.0
    mun = 0.0
    cost = 0

    for n in range(N):
        T = 0.0
        for j in range(K):
            T += alpha[j] * np.sqrt(Sigman * Sigma[j])
        Sigman = T

    mun += np.median(mu)

    for j in range(K):
        cost += alpha[j] * GaussianW2_1D(mu[j], mun, Sigma[j], Sigman)

    return mun, Sigman, cost

# Note: The function GaussianW2_1D needs to be defined to compute the W2 distance for 1D Gaussians.


def GaussianBarycenterW2(mu,Sigma,alpha,N):
    # Compute the W2 barycenter between several Gaussians
    # mu has size Kxd, with K the number of Gaussians and d the space dimension
    # Sigma has size Kxdxd
    K        = mu.shape[0]  # number of Gaussians
    d        = mu.shape[1]  # size of the space
    Sigman   = np.eye(d,d)
    mun      = np.zeros((1,d))
    cost = 0

    for n in range(N):
        Sigmandemi       = spl.sqrtm(Sigman)
        T = np.zeros((d,d))
        for j in range(K):
            T+= alpha[j]*spl.sqrtm(Sigmandemi@Sigma[j,:,:]@Sigmandemi)
        Sigman  = T


    mun = geometric_median(np.array(mu), eps=1e-5)

    for j in range(K):
        cost+= alpha[j]*GaussianW2(mu[j,:],mun,Sigma[j,:,:],Sigman)

    return mun,Sigman,cost       # return the Gaussian Barycenter (mun,Sigman) and the total cost

"""## Generate data"""

def ung_simul_outlier(n_datasets, n_observations, mean, std):
    datasets = []
    true_dataset = np.array([])
    for i in range(n_datasets):
        samples = np.random.normal(mean, std, size=(n_observations-1))

        # Find the maximum value in the dataset
        max_value = np.max(samples)

        # Create the outlier - a single value that is an amplified max value
        outlier = max_value *(i+1) # Adjusted to avoid multiplying by 0

        # Add the outlier to the dataset (as the last observation)
        samples_with_outlier = np.append(samples, outlier)

        # Append the dataset with the outlier to the list of datasets
        datasets.append(samples_with_outlier)

        # Concatenate samples to true_dataset
        true_dataset = np.concatenate((true_dataset, samples))
    return datasets,true_dataset


datasets,true_dataset = ung_simul_outlier(n_datasets = 2, n_observations = 100, mean = np.array([2]), std = np.array([1]))

def split_dataset_into_ten_random_parts(dataset):
    """
    Splits the dataset into ten random parts.

    Parameters:
    - dataset: A list or numpy array containing the dataset.

    Returns:
    - A list of ten numpy arrays, each being a part of the dataset.
    """

    # Convert the dataset to a numpy array if it isn't already one
    if not isinstance(dataset, np.ndarray):
        dataset = np.array(dataset)

    # Shuffle the dataset randomly
    np.random.shuffle(dataset)

    # Calculate the size of each split
    split_size = len(dataset) // 10

    # Split the dataset into 10 parts
    splits = [dataset[i:i + split_size] for i in range(0, len(dataset), split_size)]

    # Adjust the last split in case of unequal division
    if len(splits) > 10:
        last_split = splits.pop(-2) + splits.pop(-1)
        splits.append(last_split)

    return splits

split_dataset_into_ten_random_parts(datasets[0])

"""## KL for ung"""

import torch
import numpy as np
import matplotlib.pyplot as plt

def gaussian_sample(mean, std, num_samples, D=1):
    eps = torch.randn(size=(num_samples, D))
    z = eps * std + mean
    return z

def log_gaussian(x, mean, std):
    return -0.5 * torch.log(2 * np.pi * std ** 2) - (0.5 * (1 / (std ** 2)) * (x - mean) ** 2)

#def log_likelihood(x,z):
#    return -0.5 * torch.log(2 * np.pi * torch.ones_like(x)) - 0.5 * (x - z) ** 2
#log_likelihood = lambda t: -0.5 * torch.sum(torch.log(2 * np.pi * torch.ones_like(D))) - torch.sum(0.5 * (D - t) ** 2)

#likelihood
def make_likelihood_fn(D):
    def likelihood_fn(z):
        # Ensure z is a float tensor for PyTorch operations
        z = z.float()

        # Reshape D and z for broadcasting: D to (N, 1) and z to (1, M)
        D_reshaped = D.view(-1, 1)
        z_reshaped = z.view(1, -1)

        # Compute the log likelihood for each combination of D_i and z_j
        log_likelihoods = -0.5 * torch.log(2 * np.pi * torch.ones_like(D_reshaped)) - 0.5 * (D_reshaped - z_reshaped) ** 2

        # Sum over all data points for each mean in z
        sum_log_likelihoods = torch.sum(log_likelihoods, dim=0)

        return sum_log_likelihoods

    return likelihood_fn


def compute_elbo(q_means, q_stds,q_fn, p_fn,D):
    elbo = 0
    softplus = torch.nn.Softplus()
    z = gaussian_sample(q_means, q_stds, num_samples)

    q_likelihood = torch.mean(q_fn(z))
    prior = torch.mean(p_fn(z))
    D = torch.tensor(D)
    loglikelihood = make_likelihood_fn(D)

    #likelihood = torch.mean(log_likelihood(x=D,z=z))
    likelihood = torch.mean(loglikelihood(z))
    #elbo = q_likelihood - prior - likelihood
    elbo = q_likelihood - 10*likelihood

    return elbo

def kl_gg(q_means, q_stds, D,
                num_samples,  num_steps, optim=True):


    # VI post
    q_means = torch.nn.Parameter(torch.tensor(q_means), requires_grad=True)
    q_stds = torch.nn.Parameter(torch.tensor(q_stds), requires_grad=True)
    q_fn = lambda t: log_gaussian(t, q_means, q_stds)

    #prior
    p_means = torch.tensor([0.])
    p_stds = torch.tensor([10.])
    p_fn = lambda t: log_gaussian(t, p_means, p_stds)

    #likelihood
    D = torch.tensor(D)
    loglikelihood = make_likelihood_fn(D)

    optimizer = torch.optim.Adam([
    {'params': [q_means, q_stds], 'lr': 0.002}])
    for step in range(num_steps):
        loss = compute_elbo(q_means, q_stds, q_fn, p_fn, D)
        optimizer.zero_grad()
        loss.backward(retain_graph=True)
        optimizer.step()

        if step % 250 == 0 and optim == True:
            print('Step:{} Loss: {:.6f}, '
                  'means:{}, '
                  'stds:{}'
                  .format(step, loss.item(), q_means.data.numpy(),
                          q_stds.data.numpy())
                )
    return [q_means, q_stds]

"""## VI barycenter coverage"""

def VI_barycenter(n_datasets, datasets, q_means, q_stds, num_samples, num_steps):
#datasets: a list of datasets
#q_means, stds: means and std for VI
    means = []
    stds = []
    for dataset in datasets:
        learned_params = kl_gg(q_means = q_means, q_stds = q_stds, D = dataset,
                               num_samples = num_samples, num_steps = num_steps, optim = False)
        means.append(learned_params[0])
        #stds.append(learned_params[1]/10**(1/2))
        stds.append(learned_params[1])

    barymeans = [param.detach().numpy() for param in means]
    barymeans= np.array(barymeans)
    barystds = [param.detach().numpy() for param in stds]
    barystds= np.array(barystds)


    alpha = np.full(n_datasets, 1/n_datasets)
    mybarycenter = GaussianBarycenterW2_1D(barymeans,barystds,alpha,N=100)

    return mybarycenter

median_count_95 = [0]*15
true_count_95 = [0]*15
median_count_90 = [0]*15
true_count_90 = [0]*15
median_count_80 = [0]*15
true_count_80 = [0]*15
rep = 100
for i in range(rep):
    datasets,true_dataset = ung_simul_outlier(n_datasets = 25, n_observations = 100,  mean = np.array([2]), std = np.array([1]))
    for j in range(15):
        splitdatasets = split_dataset_into_ten_random_parts(datasets[j])
        q_means = torch.tensor([2.])
        q_stds = torch.tensor([1.])
        num_samples = 10
        num_steps = 1000
        barycenter = VI_barycenter(n_datasets = 10, datasets = splitdatasets, q_means = q_means, q_stds = q_stds,
                      num_samples = num_samples, num_steps =num_steps)

        barymeans = barycenter[0]
        barystds = barycenter[1]
        #print("barycenter\n")
        #print("lb=",barymeans-1.96*barystds,"\n")
        #print("up=",barymeans+1.96*barystds,"\n")
        if barymeans-1.96*barystds < 2 and barymeans+1.96*barystds > 2:
            median_count_95[j] += 1
        if barymeans-1.645*barystds < 2 and barymeans+1.645*barystds > 2:
            median_count_90[j] += 1
        if barymeans-1.2816*barystds < 2 and barymeans+1.2816*barystds > 2:
            median_count_80[j] += 1
        learned_params = kl_gg(q_means = q_means, q_stds = q_stds, D = datasets[j],
                          num_samples = num_samples, num_steps = num_steps, optim = False)
        truemeans = learned_params[0]
        truestds = learned_params[1]
        #print("truth\n")
        #print("lb=",truemeans-1.96*truestds,"\n")
        #print("up=",truemeans+1.96*truestds,"\n")
        if truemeans-1.96*truestds < 2 and truemeans+1.96*truestds > 2:
            true_count_95[j] += 1
        if truemeans-1.645*truestds < 2 and truemeans+1.645*truestds > 2:
            true_count_90[j] += 1
        if truemeans-1.2816*truestds < 2 and truemeans+1.2816*truestds > 2:
            true_count_80[j] += 1

median_coverage_95 = np.array(median_count_95)/100
true_coverage_95 = np.array(true_count_95)/100
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, median_coverage_95, label='median posterior coverage')
plt.scatter(x_values, true_coverage_95, label='True posterior coverage')

plt.axhline(y=0.95, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

median_coverage_90 = np.array(median_count_90)/100
true_coverage_90 = np.array(true_count_90)/100
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, median_coverage_90, label='median posterior coverage')
plt.scatter(x_values, true_coverage_90, label='True posterior coverage')

plt.axhline(y=0.9, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

median_coverage_80 = np.array(median_count_80)/100
true_coverage_80 = np.array(true_count_80)/100
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, median_coverage_80, label='median posterior coverage')
plt.scatter(x_values, true_coverage_80, label='True posterior coverage')

plt.axhline(y=0.8, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

"""## Bayesian coverage"""

!pip install cmdstanpy

import cmdstanpy
cmdstanpy.install_cmdstan()

model_code = """
data {
  int<lower=0> N;         // Number of data points
  vector[N] y;            // The observations
}

parameters {
  real mu;                // Mean of the normal distribution
}
model {
  y ~ normal(mu, 1);    // Likelihood
}
"""

# Save your model code to a .stan file
model_file = 'model.stan'
with open(model_file, 'w') as file:
    file.write(model_code)

# Compile the model
from cmdstanpy import CmdStanModel
model = CmdStanModel(stan_file=model_file)

datasets,true_dataset = ung_simul_outlier(n_datasets = 25, n_observations = 100,  mean = np.array([2]), std = np.array([1]))
data = {
    'N': len(true_dataset),  # Example data size
    'y': true_dataset  # Replace with your actual data
}

# Compile the Stan model
fit = model.sample(data=data, chains=2, iter_sampling=1000)

mu_list=[]
std_list=[]
for i in range(n_datasets):
    data = {
    'N': len(datasets[i]),  # Example data size
    'y': datasets[i]  # Replace with your actual data
    }

    # Compile the Stan model
    fit = model.sample(data=data, chains=2, iter_sampling=1000)
    df = fit.summary()
    mu_summary = df.loc['mu']

    # Print the summary for 'mu'
    print(mu_summary)
    mu_mean = mu_summary['Mean']
    mu_list.append(mu_mean)
    mu_std = mu_summary['StdDev']
    std_list.append(mu_std)

def Bayes_barycenter(n_datasets, datasets):
#datasets: a list of datasets
#q_means, stds: means and std for VI
    means = []
    stds = []
    for dataset in datasets:
        data = {
                'N': len(dataset),  # Example data size
                'y': dataset  # Replace with your actual data
               }
        fit = model.sample(data=data, chains=2, iter_sampling=1000)
        df = fit.summary()
        mu_summary = df.loc['mu']
        means.append(mu_summary['Mean'])
        stds.append(mu_summary['StdDev'])

    barymeans = [param for param in means]
    barymeans= np.array(barymeans)
    barystds = [param/10**(1/2) for param in stds]
    barystds= np.array(barystds)


    alpha = np.full(n_datasets, 1/n_datasets)
    mybarycenter = GaussianBarycenterW2_1D(barymeans,barystds,alpha,N=100)

    return mybarycenter

datasets,true_dataset = ung_simul_outlier(n_datasets = 25, n_observations = 100,  mean = np.array([2]), std = np.array([1]))
j = 10
splitdatasets = split_dataset_into_ten_random_parts(datasets[j])

np.mean(datasets[24])

dataset = splitdatasets[4]

np.mean(splitdatasets[4])

data = {
                'N': len(dataset),  # Example data size
                'y': dataset  # Replace with your actual data
               }
fit = model.sample(data=data, chains=2, iter_sampling=1000)

median_count_95 = [0]*15
true_count_95 = [0]*15
median_count_90 = [0]*15
true_count_90 = [0]*15
median_count_80 = [0]*15
true_count_80 = [0]*15

b_median_count_95 = [0]*15
b_true_count_95 = [0]*15
b_median_count_90 = [0]*15
b_true_count_90 = [0]*15
b_median_count_80 = [0]*15
b_true_count_80 = [0]*15
rep = 50
for i in range(rep):
    datasets,true_dataset = ung_simul_outlier(n_datasets = 25, n_observations = 100,  mean = np.array([2]), std = np.array([1]))
    for j in range(15):
        splitdatasets = split_dataset_into_ten_random_parts(datasets[j])

        #median
        #VI
        q_means = torch.tensor([2.])
        q_stds = torch.tensor([1.])
        num_samples = 10
        num_steps = 1000
        barycenter = VI_barycenter(n_datasets = 10, datasets = splitdatasets, q_means = q_means, q_stds = q_stds,
                      num_samples = num_samples, num_steps =num_steps)
        barymeans = barycenter[0]
        barystds = barycenter[1]
        if barymeans-1.96*barystds < 2 and barymeans+1.96*barystds > 2:
            median_count_95[j] += 1
        if barymeans-1.645*barystds < 2 and barymeans+1.645*barystds > 2:
            median_count_90[j] += 1
        if barymeans-1.2816*barystds < 2 and barymeans+1.2816*barystds > 2:
            median_count_80[j] += 1


        ##bayes
        b_barycenter = Bayes_barycenter(n_datasets = 10, datasets = splitdatasets)
        b_barymeans = b_barycenter[0]
        b_barystds = b_barycenter[1]
        if b_barymeans-1.96*b_barystds < 2 and b_barymeans+1.96*b_barystds > 2:
            b_median_count_95[j] += 1
        if b_barymeans-1.645*b_barystds < 2 and b_barymeans+1.645*b_barystds > 2:
            b_median_count_90[j] += 1
        if b_barymeans-1.2816*barystds < 2 and b_barymeans+1.2816*b_barystds > 2:
            b_median_count_80[j] += 1


        #truth
        ##VI

        learned_params = kl_gg(q_means = q_means, q_stds = q_stds, D = datasets[j],
                          num_samples = num_samples, num_steps = num_steps, optim = False)
        truemeans = learned_params[0]
        truestds = learned_params[1]

        if truemeans-1.96*truestds < 2 and truemeans+1.96*truestds > 2:
            true_count_95[j] += 1
        if truemeans-1.645*truestds < 2 and truemeans+1.645*truestds > 2:
            true_count_90[j] += 1
        if truemeans-1.2816*truestds < 2 and truemeans+1.2816*truestds > 2:
            true_count_80[j] += 1

        ##Bayes
        data = {
                'N': len(datasets[j]),  # Example data size
                'y': datasets[j]  # Replace with your actual data
               }
        fit = model.sample(data=data, chains=2, iter_sampling=1000)
        df = fit.summary()
        mu_summary = df.loc['mu']
        b_truemeans = mu_summary['Mean']
        b_truestds = mu_summary['StdDev']
        print("b_barycenter\n")
        print("lb=",b_barymeans-1.96*b_barystds,"\n")
        print("up=",b_barymeans+1.96*b_barystds,"\n")
        print("b_truth\n")
        print("lb=",b_truemeans-1.96*b_truestds,"\n")
        print("up=",b_truemeans+1.96*b_truestds,"\n")
        if b_truemeans-1.96*b_truestds < 2 and b_truemeans+1.96*b_truestds > 2:
            b_true_count_95[j] += 1
        if b_truemeans-1.645*b_truestds < 2 and b_truemeans+1.645*b_truestds > 2:
            b_true_count_90[j] += 1
        if b_truemeans-1.2816*b_truestds < 2 and b_truemeans+1.2816*b_truestds > 2:
            b_true_count_80[j] += 1



"""## plot

### VI
"""

median_coverage_95 = np.array(median_count_95)/50
true_coverage_95 = np.array(true_count_95)/50
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, median_coverage_95, label='median posterior coverage')
plt.scatter(x_values, true_coverage_95, label='True posterior coverage')

plt.axhline(y=0.95, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

median_coverage_90 = np.array(median_count_90)/50
true_coverage_90 = np.array(true_count_90)/50
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, median_coverage_90, label='median posterior coverage')
plt.scatter(x_values, true_coverage_90, label='True posterior coverage')

plt.axhline(y=0.9, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

median_coverage_80 = np.array(median_count_80)/50
true_coverage_80 = np.array(true_count_80)/50
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, median_coverage_80, label='median posterior coverage')
plt.scatter(x_values, true_coverage_80, label='True posterior coverage')

plt.axhline(y=0.8, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

"""### bayes"""

b_median_coverage_95 = np.array(b_median_count_95)/50
b_true_coverage_95 = np.array(b_true_count_95)/50
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, b_median_coverage_95, label='median posterior coverage')
plt.scatter(x_values, b_true_coverage_95, label='True posterior coverage')

plt.axhline(y=0.95, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

b_median_coverage_90 = np.array(b_median_count_90)/50
b_true_coverage_90 = np.array(b_true_count_90)/50
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, b_median_coverage_90, label='median posterior coverage')
plt.scatter(x_values, b_true_coverage_90, label='True posterior coverage')

plt.axhline(y=0.9, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()

b_median_coverage_80 = np.array(b_median_count_80)/50
b_true_coverage_80 = np.array(b_true_count_80)/50
import matplotlib.pyplot as plt

# Data
x_values = list(range(1, 16))  # x values from 1 to 15
plt.figure(figsize=(10, 6))
plt.scatter(x_values, b_median_coverage_80, label='median posterior coverage')
plt.scatter(x_values, b_true_coverage_80, label='True posterior coverage')

plt.axhline(y=0.8, color='r', linestyle='--', label='expected coverage')

plt.title('Variational posterior coverage for Gaussian model', fontsize=14)
plt.xlabel('magnitude of outlier', fontsize=14)
plt.ylabel('coverage', fontsize=14)
plt.xticks(x_values)  # Ensure all x values are shown
plt.ylim(-0.05, 1)  # Setting the y-axis limit
plt.legend(fontsize=14)
plt.grid(True)
plt.show()